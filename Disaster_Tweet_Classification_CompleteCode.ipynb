# Import libraries
import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from gensim.models import Word2Vec
from transformers import pipeline
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
from tqdm import tqdm

# Download NLTK resources
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# Load dataset
data = pd.read_csv('train.csv')
data.head()

# Data cleaning
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'@\w+', '', text)     # Remove mentions
    text = re.sub(r'#', '', text)        # Remove hashtags
    text = re.sub(r'[^A-Za-z\s]', '', text)  # Remove punctuation
    text = text.lower()  # Lowercase
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# Apply cleaning
data['cleaned_text'] = data['text'].apply(clean_text)

# Word2Vec model
tokenized_sentences = [nltk.word_tokenize(text) for text in data['cleaned_text']]
word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)

# Zero-Shot Classification
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

def batch_zero_shot_classify(texts, batch_size=8):
    labels = ["disaster", "non-disaster"]
    predictions = []
    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i + batch_size]
        results = classifier(batch.tolist(), labels)
        for res in results:
            predictions.append(res['labels'][0])
    return predictions

# Apply classification
data['predicted'] = batch_zero_shot_classify(data['text'].values)

# Evaluate
data['predicted_binary'] = data['predicted'].apply(lambda x: 1 if x == 'disaster' else 0)
accuracy = accuracy_score(data['target'], data['predicted_binary'])
print(f"Accuracy: {accuracy * 100:.2f}%")

# Visualization
data['predicted'].value_counts().plot(kind='bar', color=['green', 'red'])
plt.title('Disaster vs Non-Disaster Predictions')
plt.xlabel('Category')
plt.ylabel('Count')
plt.show()
